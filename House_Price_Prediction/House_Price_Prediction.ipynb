{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u-Ma4lrGgPtK"
   },
   "source": [
    "1. Title: Boston Housing Data\n",
    "\n",
    "2. Sources:\n",
    "   (a) Origin:  This dataset was taken from the StatLib library which is\n",
    "                maintained at Carnegie Mellon University.\n",
    "   (b) Creator:  Harrison, D. and Rubinfeld, D.L. 'Hedonic prices and the\n",
    "                 demand for clean air', J. Environ. Economics & Management,\n",
    "                 vol.5, 81-102, 1978.\n",
    "   (c) Date: July 7, 1993\n",
    "\n",
    "3. Past Usage:\n",
    "   -   Used in Belsley, Kuh & Welsch, 'Regression diagnostics ...', Wiley,\n",
    "       1980.   N.B. Various transformations are used in the table on\n",
    "       pages 244-261.\n",
    "    -  Quinlan,R. (1993). Combining Instance-Based and Model-Based Learning.\n",
    "       In Proceedings on the Tenth International Conference of Machine\n",
    "       Learning, 236-243, University of Massachusetts, Amherst. Morgan\n",
    "       Kaufmann.\n",
    "\n",
    "4. Relevant Information:\n",
    "\n",
    "   Concerns housing values in suburbs of Boston.\n",
    "\n",
    "5. Number of Instances: 506\n",
    "\n",
    "6. Number of Attributes: 13 continuous attributes (including \"class\"\n",
    "                         attribute \"MEDV\"), 1 binary-valued attribute.\n",
    "\n",
    "7. Attribute Information:\n",
    "\n",
    "    1. CRIM      per capita crime rate by town\n",
    "    2. ZN        proportion of residential land zoned for lots over\n",
    "                 25,000 sq.ft.\n",
    "    3. INDUS     proportion of non-retail business acres per town\n",
    "    4. CHAS      Charles River dummy variable (= 1 if tract bounds\n",
    "                 river; 0 otherwise)\n",
    "    5. NOX       nitric oxides concentration (parts per 10 million)\n",
    "    6. RM        average number of rooms per dwelling\n",
    "    7. AGE       proportion of owner-occupied units built prior to 1940\n",
    "    8. DIS       weighted distances to five Boston employment centres\n",
    "    9. RAD       index of accessibility to radial highways\n",
    "    10. TAX      full-value property-tax rate per $10,000\n",
    "    11. PTRATIO  pupil-teacher ratio by town\n",
    "    12. B        1000(Bk - 0.63)^2 where Bk is the proportion of blacks\n",
    "                 by town\n",
    "    13. LSTAT    % lower status of the population\n",
    "    14. MEDV     Median value of owner-occupied homes in $1000's\n",
    "\n",
    "8. Missing Attribute Values:  None."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.linear_model import LinearRegression\n",
    "# from sklearn.ensemble import RandomForestRegressor\n",
    "# from sklearn.impute import SimpleImputer\n",
    "# from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# # Load the dataset\n",
    "# df = pd.read_csv('data.csv')\n",
    "\n",
    "# # Impute missing values\n",
    "# imputer = SimpleImputer(strategy='mean')\n",
    "# df_imputed = pd.DataFrame(imputer.fit_transform(df), columns=df.columns)\n",
    "\n",
    "# # Prepare data\n",
    "# X = df_imputed.drop(['MEDV','ZN','CHAS'], axis=1)\n",
    "# y = df_imputed['MEDV']\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# # Models\n",
    "# models = {\n",
    "#     \"Linear Regression\": LinearRegression(),\n",
    "#     \"Random Forest\": RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "# }\n",
    "\n",
    "# # Train and evaluate models\n",
    "# for name, model in models.items():\n",
    "#     model.fit(X_train, y_train)\n",
    "#     y_pred = model.predict(X_test)\n",
    "#     mse = mean_squared_error(y_test, y_pred)\n",
    "#     r2 = r2_score(y_test, y_pred)\n",
    "#     print(f\"Model: {name}\")\n",
    "#     print(f\"MSE: {mse}\")\n",
    "#     print(f\"R-squared: {r2}\")\n",
    "\n",
    "#     # Visualize actual vs predicted\n",
    "#     plt.figure(figsize=(8, 6))\n",
    "#     plt.scatter(y_test, y_pred, color='blue')\n",
    "#     plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'k--', lw=2)\n",
    "#     plt.xlabel('Actual')\n",
    "#     plt.ylabel('Predicted')\n",
    "#     plt.title(f'{name} - Actual vs Predicted')\n",
    "#     plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 561
    },
    "id": "12bAABijcz8p",
    "outputId": "ec46690b-6e3e-4075-9dd2-f47ddf295066"
   },
   "outputs": [],
   "source": [
    "# # THIS IS AN EXAMPLE OF A LINEAR REGRESSION ALGORITHM OF A HOUSE PRICE PREDICTION MODEL USING THE ATTRIBUTE - NUMBER OF ROOMS IN A HOUSE\n",
    "# # Importing pandas and numpy libraries\n",
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "\n",
    "# # Importing different modules from sklearn library and matplotlib\n",
    "# from sklearn.linear_model import LinearRegression\n",
    "# from sklearn.metrics import mean_squared_error\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# # Now we have to read the csv file using read_csv function\n",
    "# df = pd.read_csv('data.csv')\n",
    "# model = LinearRegression()\n",
    "\n",
    "# # Now for little preprocessing, we will drop the null values from the dataset\n",
    "# df = df.dropna()\n",
    "\n",
    "# # It's time to fit the target variable and its dependent variable which in this case is RM.\n",
    "# model.fit(df[['RM']], df[['MEDV']])\n",
    "# predictions = model.predict(df[['RM']])\n",
    "\n",
    "# # Now we will calculate the root mean squared error\n",
    "# rmse = mean_squared_error(df['MEDV'], predictions)\n",
    "# print('RMSE:', rmse)\n",
    "\n",
    "# # Now we have to plot these using the matplotlib library and pyplot module, and we will be using a scatter plot\n",
    "# plt.scatter(df['RM'], df['MEDV'], color='orange', label='Actual Prices')\n",
    "# plt.plot(df['RM'], predictions, color='green', label='Regression Line')\n",
    "# plt.xlabel('NUMBER OF ROOMS')\n",
    "# plt.ylabel('PRICES IN 1000$s')\n",
    "# plt.title('Linear Regression: No of Rooms VS Prices of Houses')\n",
    "\n",
    "# # Plotting the predicted price for a house with new_rooms\n",
    "# plt.scatter(new_rooms, predicted_price, color='black', marker='o', label='Predicted Price')\n",
    "# plt.axvline(x=new_rooms, color='black', linestyle='--', label=f'Number of Rooms = {new_rooms}')\n",
    "# plt.axhline(y=predicted_price.item(), color='black', linestyle='--', label=f'Predicted Price = {predicted_price.item():.2f} in 1000$s')\n",
    "# plt.legend()\n",
    "# plt.show()\n",
    "\n",
    "# # Now our model is trained using linear regression. It's time to test it so we will take the number of rooms as input and the price will be predicted as output\n",
    "# new_rooms = 7\n",
    "\n",
    "# # Now we apply our model on this input to calculate the price of the house!\n",
    "# predicted_price = model.predict([new_rooms])\n",
    "# print(f'Predicted Price for House with {new_rooms} rooms: {predicted_price.item():.2f} in 1000$s')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RBF Kernel:\n",
      "Mean Squared Error: 20.524140319603422\n",
      "R2 Score: 0.7222415400691268\n",
      "Predicted Price (RBF Kernel): 22.389266663339292\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('data.csv')\n",
    "df = df.dropna()\n",
    "selected_attributes = ['CRIM','INDUS','RM','AGE','DIS','TAX']\n",
    "X = df[selected_attributes]\n",
    "y = df['MEDV']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "svm_rbf = SVR(kernel='rbf')\n",
    "svm_rbf.fit(X_train_scaled, y_train)\n",
    "\n",
    "y_pred_rbf = svm_rbf.predict(X_test_scaled)\n",
    "\n",
    "print(\"RBF Kernel:\")\n",
    "print(\"Mean Squared Error:\", mean_squared_error(y_test, y_pred_rbf))\n",
    "print(\"R2 Score:\", r2_score(y_test, y_pred_rbf))\n",
    "\n",
    "sample_data = pd.DataFrame({\n",
    "    'CRIM': [0.02731],\n",
    "    'INDUS': [7.07],\n",
    "    'RM': [6.421],\n",
    "    'AGE': [78.9],\n",
    "    'DIS': [4.9671],\n",
    "    'TAX': [242],\n",
    "})\n",
    "\n",
    "sample_data_scaled = scaler.transform(sample_data)\n",
    "predicted_price_rbf = svm_rbf.predict(sample_data_scaled)\n",
    "print(\"Predicted Price (RBF Kernel):\", predicted_price_rbf[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('model.pkl', 'wb') as f:\n",
    "    pickle.dump(df, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
